Тест знаний Hadoop
==================

Введение в тест по Apache Hadoop
--------------------------------

Apache Hadoop - фреймворк с открытым исходным кодом, в котором реализована вычислительная парадигма, известная как MapReduce. Изначально Apache Hadoop начинался с проекта Nutch, который представлял собой систему веб-поиска с открытым кодом, работавшую на двадцати машинах. Затем проектом заинтересовалась компания Yahoo! и проект получил своё дальнейшее развитие, сменив название на "Hadoop". В 2008 году проект Hadoop стал одним из ведущих проектов Apache, что доказало его успех и наличие разнообразного, активного сообщества. К этому времени технология Hadoop  использовалась не только в Yahoo!, но и во многих других компаниях - например, в Last.fm Facebook и New Yorks Times. На данный момент фреймворк Apache Hadoop используется хранения и анализа обработки больших количеств данных (десятки и сотни терабайт) самыми разнообразными компаниями.

Целевая аудитория теста по Apache Hadoop
----------------------------------------

Тест содержит вопросы, знакомые большинству разработчиков, применяющих Apache Hadoop в своей повседневной практике и предназначен прежде всего для начинающих разработчиков, только осваивающих Apache Hadoop. 

Предварительные требования к тесту Apache Hadoop
------------------------------------------------

Для желающих успешно пройти тест необходимо знание языка программирования Java, опыт установки, конфигурирования кластера, запуск распределённых задач на узлах кластера Apache Hadoop. Реальный опыт работы с кластером, состоящим из нескольких узлов будет преимуществом, хотя для понимания сути и нахождения правильных ответов на вопросы теста достаточно работы с кластером, состоящим из одного узла: так называемый псевдо-распределённый режим работы кластера.

Структура теста по Apache Hadoop
--------------------------------

Тест охватывает следующие темы:
* Методология вычислений MapReduce;
* Файловая система HDFS;
* Ввод/вывод в Hadoop;
* Hadoop API и разработка приложений MapReduce;
* Типы и форматы данных в MapReduce;
* Классическая и YARN архитектура кластера
* Конфигурация и администрирование кластера Hadoop.

Прохождение теста позволяет систематизировать знания по Apache Hadoop и подготовить разработчиков к практической работе с кластером.


---------------------------------------------------------------------------------
Вопрос №1: Что такое HadoopStreaming?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Способ написания Java программ в модели вычислений  MapReduce, при котором выходные данные одной программы являются входом для другой.
Вариант2: Технология, использующая стандартные потоки воода/вывода Unix для организации взаимодействия Hadoop с другими программами.
Вариант3: Такое понятие как HadoopStreaming вообще не существует.
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №2: Возможно ли в рамках проекта Hadoop запустить задание (Job), написанное на языке отличном от Java?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Да
Вариант2: Нет
Правильный ответ: 1
Пояснение: Для запуска задания (Job) в рамках проекта Hadoop на языке, отличном от Java используется технология HadoopStreaming.


---------------------------------------------------------------------------------
Вопрос №3: Является ли модель программирования MapReduce линейно масштабируемой?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Да
Вариант2: Нет
Правильный ответ: 1
Пояснение: 


---------------------------------------------------------------------------------
Вопрос №4: В чём отличие системы хранения и анализа данных Hadoop от реляционной СУБД? Выберите все подходящие варианты ответа.
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Реляционные СУБД используют как интерактивный, так и пакетный режим доступа, в то время как Hadoop - только пакетный.
Вариант2: Реляционные СУБД позволяют выполнять многократное чтение и запись данных, в то время как Hadoop - однокаратную запись и многократное чтение.
Вариант3: Реляционные СУБД работают только со структурированными наборами данных, в то время как Hadoop использует слабо и неструктурированные данные.
Вариант4: Реляционные СУБД масштабируются линейно, в то время как Hadoop - нелинейно.
Правильный ответ:1,2,3
Пояснение:



---------------------------------------------------------------------------------
Вопрос №5: Что такое HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Распределённая столбцово-ориентированная база данных.
Вариант2: Язык управления потоком данных и исполнительная среда для анализа очень больших наборов данных.
Вариант3: Распределённая файловая система, работающая на больших кластерах из стандартных машин.
Правильный ответ: 3
Пояснение:



---------------------------------------------------------------------------------
Вопрос №6: Каков размер блока HDFS по умолчанию?
---------------------------------------------------------------------------------
Тип: Radio 
Вариант1: 512 байт
Вариант2: 64 Мбайт
Вариант3: 256 Мбайт
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №7: Какова основная функция вторичного узла имён (Secondary Name Node)?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Переодическое слияние образа пространства имён с журналом изменений.
Вариант2: Резервное восстановление функциональности узла имён после отказа главного узла имён.
Вариант3: Хранение дополнительных метаданных кластера.
Правильный ответ: 1
Пояснение:


---------------------------------------------------------------------------------
Вопрос №8: Чему равен коэффициент репликации для каталогов в файловой системе HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: 3
Вариант2: Каталоги не реплицируется
Вариант3: 1
Правильный ответ: 2
Пояснение:



---------------------------------------------------------------------------------
Вопрос №9: Где хранится информация о местонахождении блоков в файловой системе HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: На узле имён
Вариант2: На узлах данных в форме списков блоков, которые на них хранятся
Вариант3: В локальной файловой системе вторичного узла имён (Secondary Name Node)
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №10: Какие типы узлов существуют в кластере HDFS?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Узел имён
Вариант2: Узел репликаций
Вариант3: Узел контрольных точек
Вариант4: Узел метаданных
Вариант5: Узел данных
Правильный ответ: 1,5
Пояснение:


---------------------------------------------------------------------------------
Вопрос №11: Для чего предназначена технология HDFS Federation?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Для записи функций отображения и свёртки на других языках, отличных от Java
Вариант2: Для использования сокетов в качестве каналов, по которым трекер задач взаимодействует с процессами
Вариант3: Для масштабирования кластера за счёт добавления узлов имён, каждый из которых управляет частью пространства имён файловой системы
Вариант4: Ни один из указанных вариантов
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №12: Для каких областей применения HDFS подходит не лучшим образом? Выберите все правильные варианты.
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Множественные источники записи в файлы
Вариант2: Работа с многочисленными мелкими файлами
Вариант3: Необходимость быстрого доступа к данным
Вариант4: Необходимость произвольной модификации файлов
Правильный ответ:1,2,3,4
Пояснение:


---------------------------------------------------------------------------------
Вопрос №14: Почему блоки файловой системы HDFS такие большие по сравнению с обычной файловой системой?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Это уменьшает размер узла имён
Вариант2: Это упрощает репликацию данных
Вариант3: Это сводит к минимуму количество операций позиционирования головки жёсткого диска
Правильный ответ: 3
Пояснение: При достаточно большом размере блока время передачи данных с диска может быть намного больше времени позиционирования к началу блока. Таким образом, время передачи большого файла, состоящего из многих блоков, определяется скоростью передачи данных.


---------------------------------------------------------------------------------
Вопрос №15: Что содержит файл образа файловой системы HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Сериализированную форму метаданных о файле или каталоге, а также информацию о том, на каких узлах хранятся блоки
Вариант2: Сериализированную форму метаданных о файле или каталоге без информации о расположении блоков
Вариант3: HDFS не использует файл образа файловой системы, а динамически получает её из журнала изменений
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №16: Для чего предназначена комбинирующая функция?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Для комбинирования нескольких заданий кластера в единый поток выполнения, когда выход одного задания является входом другого
Вариант2: Для расчёта наилучшей комбинации хранения разных реплик файла на узлах данных, при которой достигается максимальная надёжность хранения
Вариант3: Для сведения к минимуму передачи данных между задачами отображения (Map) и свёртки (Reduce)
Правильный ответ: 3
Пояснение:



---------------------------------------------------------------------------------
Вопрос №17: Сколько места в HDFS занимает файл, если размер файла меньше размера блока HDFS? 
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Размер файла в HDFS в этом случае равен размеру блока
Вариант2: Размер файла в HDFS в этом случае равен исходному размеру файла
Вариант3: Файлы размером меньше размера блока сцепляются в последовательности и хранятся в одном блоке. В этом случае размер файла равен суммарному размеру всех сцепленных в одном блоке файлов
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №18: Зависит ли количество задач свёртки (Reduce) от размера входных данных?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Да
Вариант2: Нет
Правильный ответ: 2
Пояснение: Количество задач свёртки (Reduce) задаётся отдельно. По умолчанию в Hadoop задаётся одна задача свёртки. Оптимальное количество свёрток связано с общим количеством слотов свёртки в кластере. Задаётся в классе JobConf в методе setNumReduceTasks(int num)


---------------------------------------------------------------------------------
Вопрос №19: От чего зависит количество задач отображения (Map) в задании кластера, если входные файлы хранятся в HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: От количества сплитов (split), в которые преобразуются входные данные
Вариант2: От фактора репликации файлов кластера
Вариант3: От абсолютного размера файлов входных данных
Вариант4: От отношения общего размера входных данных к числу файлов, составляющих эти данные
Правильный ответ: 1
Пояснение: Количество задач отображения (Map) зависит от количества сплитов (split), которое определяется размером входных данных и размером блока, если входные файлы хранятся в HDFS



---------------------------------------------------------------------------------
Вопрос №20: Выберите общую форму функций отображения и свёртки в Hadoop MapReduce?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: map: (K1, V1) -> list(K2, V2)
          reduce: (K2, V2) -> list(K3, V3)
Вариант2: map: (K1, V1) -> list(K2, V2)
          reduce: (K2, list(V2)) -> list(K3, V3) 
Вариант3: map: (K1, V1) -> list(K2, V2)
          reduce: (K2, list(V2)) -> (K3, V3) 
Вариант4: map: (K1, V1) -> (K2, V2)
          reduce: (K2, V2) -> (K3, V3) 
Правильный ответ: 2
Пояснение:



---------------------------------------------------------------------------------
Вопрос №21: Как связаны между собой типы данных ключа и значения в процессах отображения (Map) и свёртки (Reduce)?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Типы входных данных свёртки (Reduce) могут не совпадать с выходными типами отображения (Map)
Вариант2: Типы входных данных свёртки (Reduce) могут совпадать с выходными типами отображения (Map)
Вариант3: Типы входных данных свёртки (Reduce) должны совпадать с выходными типами отображения (Map) 
Вариант4: Типы входных данных свёртки (Reduce) должны не совпадать с выходными типами отображения (Map) 
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №22: Что такое сплит (split)?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Это фрагмент входных данных, обрабатываемый одной задачей отображения
Вариант2: Это фрагмент входных данных, хранящийся на одном узле кластера
Вариант3: Это фрагмент входных данных, размер которого равен размеру одного файла данных
Правильный ответ: 1
Пояснение:


---------------------------------------------------------------------------------
Вопрос №23: Назовите базовый класс для всех реализаций InputFormat, использующих файлы в качестве источника данных
---------------------------------------------------------------------------------
Тип: Text
Правильный ответ: FileInputFormat
Пояснение:



---------------------------------------------------------------------------------
Вопрос №24: Дана структура каталогов в HDFS:

/test-input-folder
    /subfolder
       file-0001.data
       file-0002.data
    file-0001.data
    file-0002.data

С помощью метода setIputPaths() директория /test-input-folder задана в качестве входной директории для задания (Job). Задание написано таким образом, чтоб подсчитать количество слов во входных данных. При работе с входным каталогом использованы настройки задания по умолчанию. Что произойдет при попытке запуска задания?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Задание успешно выполниться
Вариант2: Ошибка в ходе выполнения задания. В именах файлов в HDFS запрещено использовать символ "-"
Вариант3: Ошибка в ходе выполнения задания. Имена файлов должны быть уникальными во всей файловой системе HDFS
Вариант4: Ошибка в ходе выполнения задания. Расширения для файлов в HDFS не используются
Вариант5: Ошибка в ходе выполнения задания. Содержимое каталога не обрабатывается рекурсивно
Вариант6: Указанную структуру файлов создать невозможно. В HDFS используются только файлы, без директорий.
Правильный ответ: 5
Пояснение:  Содержимое каталога, заданного в качестве входного пути, не обрабатывается рекурсивно. Более того, каталог должен содержать только файлы. Если в нём содержится подкаталог, то последний будет интерпретирован как файл, что приведёт к ошибке.



---------------------------------------------------------------------------------
Вопрос №25: Что такое тасовка (shuffle)?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Процесс выполнения сортировки системой и передачи выходных данных на вход свёрток
Вариант2: Процесс определения расположения блоков файла и вычисления способа их оптимальной загрузки в память для последующей обработки
Вариант3: Процесс оптимизации хода выполнения задания за счёт определения количества свёрток и отображений
Правильный ответ: 1
Пояснение:



---------------------------------------------------------------------------------
Вопрос №26: Выберите все правильные варианты для копирования файла из локальной файловой системы в HDFS
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: hadoop fs -copy <src> <dst>
Вариант2: hadoop fs -copyLocal <src> <dst>
Вариант3: hadoop fs -copyFromLocal <src> <dst>
Вариант4: hadoop fs -put <src> <dst>
Вариант5: hadoop fs -putLocal <src> <dst>
Вариант6: hadoop fs -putFromLocal <src> <dst>
Правильный ответ: 3,4
Пояснение:


---------------------------------------------------------------------------------
Вопрос №27: Выберите команду, изменяющую фактор репликации в файле
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: hadoop fs -rep -w <numReplicas> <path>
Вариант2: hadoop fs -replica -w <numReplicas> <path>
Вариант3: hadoop fs -setrep -w <numReplicas> <path>
Вариант4: hadoop fs -chrep -w <numReplicas> <path>
Вариант5: Фактор репликации нельзя изменить для одного файла, а можно только для всех файлов файловой системы
Вариант6: Ни один из указанных вариантов
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №28: Какая команда выведет содержимое файла, находящегося в HDFS, на экран?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: hadoop fs -cat <path>
Вариант2: hadoop fs -text <path> 
Вариант3: hadoop fs -print <path>
Вариант4: Ни один из указанных вариантов
Правильный ответ:1, 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №29: Что делает команда hadoop fs -move <localsrc> <dst>?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Такой команды не существует
Вариант2: Перемещает файл из локальной файловой системы в HDFS
Вариант3: Перемещает (переименовывает) файл из одной директории в HDFS в другую директорию в HDFS 
Вариант4: Ни один из указанных вариантов
Правильный ответ: 1
Пояснение: hadoop fs -moveFromLocal <localsrc> <dst> команда перемещает файл из локальной файловой системы в HDFS
          hadoop fs -mv <scr> <dst> команда перемещает (переименовывает) файл из одной директории в HDFS в другую директорию в HDFS 



---------------------------------------------------------------------------------
Вопрос №30: Что делает команда hadoop fs -h?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Печатает справку по использованию команд hadoop
Вариант2: Вместе с аргументом <hostname> после параметра -h задёт хост узла имён
Вариант3: Вместе с аргументом <file> после параметра -h печатает заголовок файла в HDFS
Вариант4: Ни один из указанных вариантов
Правильный ответ: 4
Пояснение:Такой команды не существует


---------------------------------------------------------------------------------
Вопрос №31: Для чего используется разрешение исполнения (x) для файлов в HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Разрешение исполнения для файлов в HDFS игнорируется
Вариант2: Разрешение исполнения присваивается файлам с расширением *.jar для того, что задания (Job) могли использовать эти файлы
Вариант3: Разрешение исполнения присваивается файлам с расширением *.jar, *.zip и другим архивным файлам для их успешной распаковки в HDFS
Правильный ответ: 1
Пояснение:



---------------------------------------------------------------------------------
Вопрос №32: Как называется инструмент архивации файлов, повышающий эффективность упаковки файлов в блоки HDFS?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: HDFS-AR
Вариант2: HAR
Вариант3: HZIP
Вариант4: MR_ARCHIVE
Вариант5: HARJ
Правильный ответ: 2
Пояснение: HAR сокращение от Hadoop ARchives. Архив создаётся из набора файлов программой archive. Программа запускает задание MapReduce для параллельной обработки входных файлов, соответственно, для её запуска необходим работающий кластер MapReduce.


---------------------------------------------------------------------------------
Вопрос №33: Для чего в HDFS применяется инструмент архивации файлов HAR?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Для уменьшения места, которое занимают файлы в HDFS
Вариант2: Для уменьшения трафика между узлами данных
Вариант3: HAR не применяется в HDFS
Вариант4: Ни один из указанных вариантов
Правильный ответ: 4
Пояснение: Архив, полученный с помощью HAR, не занимает меньше места, чем исходный файл. Архивация HAR не сжимает файлы, а объединяет множество мелких файлов в один крупный. Таким образом уменьшается нагрузка на узел данных, поскольку слишком слишком большое число мелких файлов приводит к чрезмерному разрастанию образа файловой системы. 



---------------------------------------------------------------------------------
Вопрос №34: Какая метрика используется как расстояние между двумя узлами локальной сети кластера HADOOP?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: В качестве метрики используется пропускная способность канала между всеми парами узлов. Значения пропускной способности вычисляется эмпирически специальной утилитой. Чем больше пропускная способность, тем ближе два узла
Вариант2: Сеть представлена в виде дерева, а расстояние оценивается как сумма расстояний до ближайшего общего предка. Дерево включает уровни, соответствующие центру обработки данных, сегменту и узлу, на котором работает процесс
Вариант3: Кластер представлен в виде взвешенного графа, где узлы графа - узлы данных, ребра - каналы связи, а веса рёбер - произвольные значения, которые задаёт администратор кластера исходя из эмпирических знаний о кластере. Вся структрура хранится в специальном конфигурационном файле кластера
Вариант4: Ни один из указанных вариантов
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №35: Каким образом по отношению к пользователю HDFS реализовано вычисление контрольных сумм файлов?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: В HDFS не используется вычисление контрольных сумм файлов
Вариант2: Вычисление контрольных сумм файлов должно производится явно с использованием класса ChecksumFileSystem
Вариант3: В HDFS организовано прозрачное вычисление контрольных сумм всех записываемых данных
Вариант4: Для вычисления контрольных сумм файлов необходимо свойству fs.file.impl задать значение apache.hadoop.fs.RawLocalFileSystem. В этом случае HDFS будет использовать механизмы локальной файловой системы для подсчета контрольных сумм
Вариант5: Ни один из указанных вариантов
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №36: Как называется собственный формат сериализации в Hadoop?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: HadoopSer
Вариант2: HadoopAvro
Вариант3: Writable
Вариант4: Avro
Вариант5: HSerializable
Вариант5: HSer
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №37: Выберите все классы, имплементирующие интерфейс Writable
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: BoolWritable
Вариант2: BooleanWritable
Вариант3: StringWritable
Вариант4: Text
Вариант5: IntWritable
Вариант6: IntegerWritable
Правильный ответ:2,4,5
Пояснение:

---------------------------------------------------------------------------------
Вопрос №38: Для чего в Hadoop используется класс SequenceFile?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Для хранения в файловой системе HDFS двоичных пар "ключ-значение"
Вариант2: Для хранения в файловой системе HDFS автоинкрементирующегося ключа и значения произвольного типа
Вариант3: Для хранения в файловой системе HDFS автоинкрементирующегося ключа и значения текстового типа
Правильный ответ: 1
Пояснение:


---------------------------------------------------------------------------------
Вопрос №39: Какая система аутентифиации применяется по умолчанию в Hadoop?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Kerberos
Вариант2: SSL
Вариант3: SASL
Вариант4: Ни один из указанных вариантов
Правильный ответ: 4
Пояснение: По умолчанию в Hadoop система аутентифиации не применяется


---------------------------------------------------------------------------------
Вопрос №40: Экземпляром какого класса представлен файл в файловой системе Hadoop?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: File
Вариант2: Path
Вариант3: HDFSFile
Вариант4: FileSystem
Правильный ответ: 2
Пояснение:


---------------------------------------------------------------------------------
Вопрос №41: Каким образом можно вставить данные в заданную позицию в середине уже существующего файла в HDFS?
---------------------------------------------------------------------------------
Тип: Radio, CheckBox
Вариант1: Используя метод transferTo(long position, long count, WritableByteHDFSChannel target) класса HDFSFileChannel
Вариант2: Используя метод append(Path f, long position) класса FSDataOutputStream
Вариант3: В HDFS это не реализовано
Правильный ответ:
Пояснение: HDFS поддерживает только последовательную запись в открытый файл или присоединение данных к уже записанному файлу



---------------------------------------------------------------------------------
Вопрос №42: Для чего предназначена утилита distcp?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Для параллельного копирования больших объёмов данных из локальной файловой системы в HDFS
Вариант2: Для параллельного копирования образа файловой системы между основным узлом имён и резервным
Вариант3: Для параллельного копирования больших объёмов данных между кластерами Hadoop
Вариант4: Ни один из указанных вариантов
Правильный ответ: 3
Пояснение:

---------------------------------------------------------------------------------
Вопрос №43: Экземпляр класса Configuration (из пакета org.apache.hadoop.conf) представляет собой коллекцию конфигурационных свойств и их значений. Как задать неизменяемое (final) свойство?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Записать в conf.xml файле с настройками и вызвать метод addResource("conf.xml") экземпляра Configuration
<property>
    <name>propertyName</name>
    <value>propertyValue</value>
    <final>true</final>
</property>
Вариант2: Записать в *xml файле с настройками и вызвать метод readConf("conf.xml") экземпляра Configuration
<property>
    <name>propertyName</name>
    <value>propertyValue</value>
    <type>final</type>
</property>
Вариант3: Вызвать метод setFinal(String propertyName, bool isFinal) экземпляра Configuration
Вариант4: Неизменяемое свойство в объекте Configuration задать невозможно
Правильный ответ: 1
Пояснение:


---------------------------------------------------------------------------------
Вопрос №44:  В следующем фрагменте кода используется класс Configuration (из пакета org.apache.hadoop.conf). Чему будет равно значение свойства property, определённого в двух конфигурационных файлах conf-1.xml и conf-2.xml

conf-1.xml:
<configuration>
    <property>
        <name>property</name>
        <value>AAA</value>
        <type>final</type>
    </property>
</configuration>

conf-2.xml:
<configuration>
    <property>
        <name>property</name>
        <value>BBB</value>
    </property>
</configuration>

после выполнения следующего фрагмента кода:

public class App {
    public static void main( String[] args ){
        Configuration conf = new Configuration();
        conf.addResource("conf-1.xml");
        conf.addResource("conf-2.xml");
        System.out.println(conf.get("property"));
    }
}
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: AAA
Вариант2: BBB
Вариант3: Ни один из указанных вариантов
Правильный ответ:2
Пояснение: Тэга <type>final</type> не существует. При выполнении строки conf.addResource("conf-2.xml"); значение property станет равным BBB. Для задания неизменяемых свойств используется тэг <final></final> со значением true строчными (маленькими) литерами.



---------------------------------------------------------------------------------
Вопрос №45:  В следующем фрагменте кода используется класс Configuration (из пакета org.apache.hadoop.conf). Чему будет равно значение свойства property, определённого в двух конфигурационных файлах conf-1.xml и conf-2.xml

conf-1.xml:
<configuration>
    <property>
        <name>property</name>
        <value>AAA</value>
        <final>true</final>
    </property>
</configuration>

conf-2.xml:
<configuration>
    <property>
        <name>property</name>
        <value>BBB</value>
    </property>
</configuration>

после выполнения следующего фрагмента кода:

public class App {
    public static void main( String[] args ){
        Configuration conf = new Configuration();
        conf.addResource("conf-1.xml");
        conf.addResource("conf-2.xml");
        System.out.println(conf.get("property"));
    }
}
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: AAA
Вариант2: BBB
Вариант3: Ни один из указанных вариантов
Правильный ответ:1
Пояснение: Для задания неизменяемых свойств используется тэг <final></final> со значением true строчными (маленькими) литерами. При выполнении строки conf.addResource("conf-2.xml"); перезаписи свойства property не происходит


---------------------------------------------------------------------------------
Вопрос №46:  В следующем фрагменте кода используется класс Configuration (из пакета org.apache.hadoop.conf). Чему будет равно значение свойства property, определённого в двух конфигурационных файлах conf-1.xml и conf-2.xml

conf-1.xml:
<configuration>
    <property>
        <name>property</name>
        <value>AAA</value>
        <final>TrUE</final>
    </property>
</configuration>

conf-2.xml:
<configuration>
    <property>
        <name>property</name>
        <value>BBB</value>
    </property>
</configuration>

после выполнения следующего фрагмента кода:

public class App {
    public static void main( String[] args ){
        Configuration conf = new Configuration();
        conf.addResource("conf-1.xml");
        conf.addResource("conf-2.xml");
        System.out.println(conf.get("property"));
    }
}
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: AAA
Вариант2: BBB
Вариант3: Ни один из указанных вариантов
Правильный ответ:2
Пояснение: Для задания неизменяемых свойств используется тэг <final></final> со значением true строчными (маленькими) литерами. Значение TrUE, заданное в вопросе, интерпретируется как false и происходит перезапись значения свойства в строке conf.addResource("conf-2.xml");. 



---------------------------------------------------------------------------------
Вопрос №47: Верно ли, что в кластере в псевдо-распределённом режиме кластера Hadoop задачи отображения (Map) и свёртки (Reduce) выполняются на одной виртуальной машине Java?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Да
Вариант2: Нет
Правильный ответ: 2
Пояснение:

---------------------------------------------------------------------------------
Вопрос №48: Как добавить отладочную информацию в задачи отображения (Map) или свёртки (Reduce)?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Использовать экземпляр класса org.apache.hadoop.LogFactory и его метод info("Log message")
Вариант2: Использовать экземпляр класса org.apache.hadoop.HadoopLogger и его метод append("Log message")
Вариант3: Использовать System.out.println("Log message");
Правильный ответ: 3
Пояснение: Всё, что пишется в стандартный вывод или стандартный поток ошибок, направляется в соответствующий файл журнала. Поэтому System.out.println("Log message"); запишет сообщение в журнал. Однако, обратите внимание, что при использовании Streaming стандартный вывод используется для данных отображения и свёртки, поэтому записанные в него данные в журнал не попадут. Классов org.apache.hadoop.LogFactory и org.apache.hadoop.HadoopLogger не существует.


---------------------------------------------------------------------------------
Вопрос №49: Как запустить задание MapReduce из java кода?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Вызвать метод submit() экземпляра класса JobClient
Вариант2: Вызвать метод submit() и затем start() экземпляра класса JobClient
Вариант3: Вызвать метод submit() экземпляра класса Job
Вариант4: Вызвать метод submit() и затем start() экземпляра класса Job
Вариант5: Вызвать метод submit() экземпляра класса JobClontrol
Вариант6: Вызвать метод submit() и затем start() экземпляра класса JobClontrol
Правильный ответ: 3
Пояснение:



---------------------------------------------------------------------------------
Вопрос №50: При подготовке задания (Job) к выполнению экземпляр класса JobSubmitter копирует ресурсы, необходимые для выполнения задания, в файловую систему трекера заданий (JobTracker). При этом один из файлов копируется с высоким коэффициентом репликации. Какой это файл?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: JAR-файл задания 
Вариант2: Конфигурационный файл задания
Вариант3: Ни один из указанных вариантов
Правильный ответ: 1
Пояснение: JAR-файл задания копируется с высоким коэффициентом репликации (определяемым свой свойством mapred.submit.replication, по умолчанию равным 10). Таким образом, в кластере появляется много копий, доступных для трекеров задач, запускающих задачи из задания


---------------------------------------------------------------------------------
Вопрос №51: Как соотносятся между собой процессы трекера заданий (JobTracker) и трекера задач (TaskTracker)?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Трекер заданий (JobTracker) является главным процессом, а трекер задач (TaskTracker) - подчинённым
Вариант2: Трекер задач (TaskTracker) является главным процессом, а трекер заданий (JobTracker) - подчинённым
Вариант3: Трекер заданий (JobTracker) и задач (TaskTracker) не соподчиняются друг другу и работают независимо
Вариант4: Ни один из указанных вариантов
Правильный ответ: 1
Пояснение:


---------------------------------------------------------------------------------
Вопрос №52: Каким образом в кластере Hadoop из командой строки можно запустить задание (Job), исполняемый код которого находится в архиве jar?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: mapred exec job <jar> [mainClass] args
Вариант2: hadoop submit job <jar> [mainClass] args
Вариант3: start job <jar> [mainClass] args
Вариант4: hadoop jar <jar> [mainClass] args
Вариант5: Ни один из указанных вариантов
Правильный ответ: 4
Пояснение:


---------------------------------------------------------------------------------
Вопрос №53: Какое количество фоновых процессов менеджера ресурсов и менеджера узлов работает при стандартной конфигурации кластера с YARN архитектурой?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Один процесс менеджера ресурсов и один или более процессов менеджера узлов (по одному на каждом узле кластера)
Вариант2: Один процесс менеджера ресурсов и один процесс менеджера узлов
Вариант3: Один или более процессов менеджера ресурсов (по одному на каждом узле кластера) и один процесс менеджера узлов
Вариант4: Один или более процессов менеджера ресурсов (по одному на каждом узле кластера) и один или более процессов менеджера узлов (по одному на каждом узле кластера)
Вариант5: Количество процессов менеджера ресурсов и менеджера узлов может быть произвольным и задаётся в конфигурации кластера в файле core-site.xml
Правильный ответ: 1
Пояснение:


---------------------------------------------------------------------------------
Вопрос №54: Для чего предназначен менеджер узлов (NodeManager) в платформе Apache Hadoop YARN?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Менеджер узлов отвечает за запуск и мониторинг состояния пользовательских приложений на узле кластера
Вариант2: Менеджер узлов отвечает за восстановление работоспособности узла после программного сбоя на нём
Вариант3: Менеджер узлов отвечает за распределение ресурсов, доступных на узле кластера
Вариант4: Ни один из указанных вариантов
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №55: Какие дополнительные задачи, кроме задач отображения (Map) и свёртки (Reduce), выполняет трекер задач (TaskTracker) при запуске задания?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Задача подготовки задания
Вариант2: Задача проверки доступности сети между узлами кластера
Вариант3: Задача деинициализации задания
Вариант4: Задача проверки прав доступа трекера задач к ресурсам задания на всех узлах кластера
Вариант5: Ни один из указанных вариантов
Правильный ответ:1,3
Пояснение: Задача подготовки задания и задача деинициализации задания выполняются трекерами задач и используются для выполнения кода, настраивающего задание до выполнения каких-либо задач отображения и осуществляющего "зачистку" после завершения всех задач свёртки



---------------------------------------------------------------------------------
Вопрос №56: Как распределены задачи отображения (Map) и свёртки (Reduce) между трекером заданий (JobTracker) и трекером задач (TaskTracker)?
---------------------------------------------------------------------------------
Тип: Radio 
Вариант1: Все задачи отображения выполняет трекер заданий, а задачи свёртки - трекер задач
Вариант2: Все задачи отображения выполняет трекер задач, а задачи свёртки - трекер заданий
Вариант3: Все задачи свёртки и отображения выполняет трекер заданий, трекер задач управляет трекером заданий  
Вариант4: Все задачи свёртки и отображения выполняет трекер задач, трекер заданий трекером управляет задач  
Правильный ответ: 4
Пояснение:


---------------------------------------------------------------------------------
Вопрос №57: Каковы задачи мастера приложений (Application Master) в кластере с архитектурой YARN?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Отслеживание прогресса задач
Вариант2: Перезапуск сбойных задач
Вариант3: Перезапуск медленно выполняемых задач
Правильный ответ:1,2,3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №58: Каким образом настроить трекер задач (TaskTracker) так, чтоб он долго выполняемую задачу не помечал как сбойную и не завершал её работу?
---------------------------------------------------------------------------------
Тип: CheckBox
Вариант1: Задать свойство mapred.task.timeout=0
Вариант2: Задать свойство mapred.task.kill.hangup.task=fasle
Вариант3: Задать свойство mapred.task.timeout=NO_TIMEOUT
Вариант4: Ни один из указанных вариантов
Правильный ответ: 1
Пояснение:



---------------------------------------------------------------------------------
Вопрос №59: Сколько попыток запустить задачу на трекере задач (JobTracker) выполняет по умолчанию трекер заданий (JobTracker), прежде чем считает задачу сбойной?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: 2
Вариант2: 3
Вариант3: 4
Правильный ответ: 3
Пояснение:


---------------------------------------------------------------------------------
Вопрос №60: Какой фоновый процесс в кластере с архитектурой YARN отслеживает сбои в мастере приложений (ApplicationMaster) и восстанавливает мастер приложений в случае сбоя?
---------------------------------------------------------------------------------
Тип: Radio
Вариант1: Трекер задач (JobTracker)
Вариант2: Трекер заданий (JobTracker)
Вариант3: Менеджер ресурсов (ResourceManager)
Вариант4: Менеджер узлов (Node Manager)
Вариант5: Менеджер высокой доступности (HA Manager)
Вариант6: Ни один из указанных вариантов
Правильный ответ: 3
Пояснение:

